{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 阶段二：寻找函数\n",
    "\n",
    "## 用 PyTorch 来实现刚才的梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个拟合函数生成数据库\n",
    "class SyntheticData(Dataset):\n",
    "    def __init__(self, generater_func):\n",
    "        self.generater_func = generater_func\n",
    "        self.pts_x = np.arange(-4.5, 4.5, 0.2).astype(np.float32)\n",
    "        self.pts_y = np.array([ generater_func(x) for x in self.pts_x]).astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pts_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'x': self.pts_x[idx], 'y': self.pts_y[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ground_truth = np.double(1.2)\n",
    "b_ground_truth = np.double(-3.7)\n",
    "c_ground_truth = np.double(4.9)\n",
    "\n",
    "target_func = lambda x: a_ground_truth * x * x + b_ground_truth * x + c_ground_truth\n",
    "data_generate_func = lambda x: target_func(x) + 10.0 * (np.double(np.random.rand()) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SyntheticData(data_generate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(sd, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们的拟合的函数还是 y = a * x * x + b * x + c\n",
    "class HypoFunc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HypoFunc, self).__init__()\n",
    "        self.a = torch.tensor(np.random.rand(), requires_grad=True)\n",
    "        self.b = torch.tensor(np.random.rand(), requires_grad=True)\n",
    "        self.c = torch.tensor(np.random.rand(), requires_grad=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predict = self.a * x * x + self.b * x + self.c\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_func = HypoFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数 Mean Square Loss\n",
    "criterion = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 提供了一个 optimizer 来实现对 a，b，c 的优化\n",
    "optimizer = torch.optim.SGD([hypo_func.a, hypo_func.b, hypo_func.c], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.0674), tensor(-3.9428), tensor(4.5898)]\n",
      "[tensor(1.2058), tensor(-4.0300), tensor(4.6029)]\n",
      "[tensor(0.9202), tensor(-3.9367), tensor(4.5876)]\n",
      "[tensor(1.0701), tensor(-3.9649), tensor(4.6031)]\n",
      "[tensor(1.1447), tensor(-3.9746), tensor(4.6069)]\n",
      "[tensor(1.0469), tensor(-3.9676), tensor(4.6046)]\n",
      "[tensor(1.0018), tensor(-3.9247), tensor(4.6083)]\n",
      "[tensor(1.2261), tensor(-3.9238), tensor(4.6201)]\n",
      "[tensor(1.0006), tensor(-3.9832), tensor(4.6009)]\n",
      "[tensor(1.1956), tensor(-4.0478), tensor(4.6073)]\n",
      "[tensor(1.1082), tensor(-4.0738), tensor(4.6010)]\n",
      "[tensor(1.0548), tensor(-4.0584), tensor(4.5953)]\n",
      "[tensor(1.2350), tensor(-3.9337), tensor(4.6015)]\n",
      "[tensor(1.0651), tensor(-4.0728), tensor(4.5896)]\n",
      "[tensor(0.9786), tensor(-3.9532), tensor(4.5932)]\n",
      "[tensor(1.0009), tensor(-3.9529), tensor(4.5905)]\n",
      "[tensor(0.9143), tensor(-3.9770), tensor(4.5842)]\n",
      "[tensor(1.1785), tensor(-4.0488), tensor(4.6034)]\n",
      "[tensor(1.0238), tensor(-3.9615), tensor(4.5916)]\n",
      "[tensor(1.0542), tensor(-3.9894), tensor(4.5941)]\n"
     ]
    }
   ],
   "source": [
    "# 跑起来\n",
    "for i in range(10000000):\n",
    "    if i%500000 == 0:\n",
    "        print([hypo_func.a.data, hypo_func.b.data, hypo_func.c.data])\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "            y_pred = hypo_func(batch['x'])\n",
    "            loss = criterion(y_pred, batch['y'])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the ground truth of [a,b,c]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.2, -3.7,  4.9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Checking the ground truth of [a,b,c]')\n",
    "np.array([1.2, -3.7, 4.9]).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
